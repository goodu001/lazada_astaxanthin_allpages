{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4c3ed2-d81f-4d55-a106-0b3b49ebb037",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install --upgrade selenium beautifulsoup4 pandas\n",
    "# If your environment has trouble fetching a driver automatically:\n",
    "# !pip -q install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471d3e60-73f8-4789-9282-164ac0179492",
   "metadata": {},
   "source": [
    "- Runs shell commands from the notebook to install packages.\n",
    "\n",
    "- ```selenium``` controls Chrome; ```beautifulsoup4``` parses HTML; ```pandas``` manages tables/CSV.\n",
    "\n",
    "- You usually don’t need ```webdriver-manager``` because Selenium Manager (built into Selenium ≥4.6) auto-handles ChromeDriver.\n",
    "\n",
    "- คำสั่งนี้ติดตั้งแพ็กเกจที่ต้องใช้: ```selenium``` สำหรับควบคุม Chrome, ```beautifulsoup4``` สำหรับอ่าน HTML, ```pandas``` สำหรับจัดการตาราง/บันทึก CSV\n",
    "\n",
    "- ปกติไม่ต้องลง ```webdriver-manager``` เพราะ Selenium Manager จะจัดการไดรเวอร์ให้อัตโนมัติ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cec2038-9da3-4f74-bbe0-121c2eba1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time, random\n",
    "from urllib.parse import quote_plus\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --------- Settings you can tweak ----------\n",
    "KEYWORD              = \"astaxanthin\"  # <- change if you want\n",
    "BASE_SEARCH_URL      = \"https://www.lazada.co.th/catalog/?q={query}&page={page}\"\n",
    "HEADLESS             = False          # True recommended for Colab/servers\n",
    "MAX_PAGES            = 50             # hard cap; we'll stop earlier if no more results\n",
    "PER_PAGE_MIN_ITEMS   = 60             # scroll each page until ~this many items visible\n",
    "PER_PAGE_MAX_SCROLLS = 20             # safety cap for scrolls per page\n",
    "SCROLL_PAUSE_RANGE   = (1.0, 2.0)     # polite random delay between scrolls (seconds)\n",
    "BETWEEN_PAGE_PAUSE   = (1.0, 2.0)     # pause between pages\n",
    "\n",
    "# Robust-ish selectors (DOM can change; we keep fallbacks)\n",
    "PRODUCT_ANCHOR_CSS = [\n",
    "    \"a[href*='/products/']\",\n",
    "    \"a[data-qa-locator='product-item']\",\n",
    "]\n",
    "NAME_CANDIDATES = [\n",
    "    \"div.RfADt\",\n",
    "    \"a[title]\",\n",
    "    \"div[data-qa-locator='product-title']\",\n",
    "]\n",
    "PRICE_CANDIDATES = [\n",
    "    \"div.aBrP0\",\n",
    "    \"span[data-qa-locator='product-price']\",\n",
    "    \"span[aria-label*='price']\",\n",
    "]\n",
    "SOLD_CANDIDATES = [\n",
    "    \"div._6uN7R\",\n",
    "]\n",
    "RATING_CANDIDATES = [\n",
    "    \"span[data-qa-locator='rating-score']\",\n",
    "    \"span[aria-label*='rating']\",\n",
    "]\n",
    "REVIEWS_CANDIDATES = [\n",
    "    \"span[data-qa-locator='rating-total']\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388f456e-8295-4ad7-bad5-22c5dc6dfd3c",
   "metadata": {},
   "source": [
    "- Imports core libs, Selenium, BeautifulSoup, and ```pandas```.\n",
    "\n",
    "- Settings:\n",
    "\n",
    "    - ```KEYWORD``` — search term.\n",
    "\n",
    "    - ```BASE_SEARCH_URL``` — we’ll navigate page by page using ```page=1,2,3,....```\n",
    "\n",
    "    - ```HEADLESS``` — set ```True``` to hide the browser window (good for Colab).\n",
    "\n",
    "    - Pagination control: ```MAX_PAGES``` (hard limit), and we’ll break early if a page yields no new products.\n",
    "\n",
    "    - Scrolling control per page: ```PER_PAGE_MIN_ITEMS```, ```PER_PAGE_MAX_SCROLLS```, ```SCROLL_PAUSE_RANGE```.\n",
    "\n",
    "    - Selectors (```*_CANDIDATES```) give multiple fallbacks for product link/name/price/sold/rating/reviews to resist minor DOM changes.\n",
    "\n",
    "\n",
    "- นำเข้าไลบรารีหลัก ๆ, Selenium, BeautifulSoup, และ ```pandas```\n",
    "\n",
    "- การตั้งค่า:\n",
    "\n",
    "    - ```KEYWORD``` — คำค้นหา\n",
    "\n",
    "    - ```BASE_SEARCH_URL``` — ใช้พารามิเตอร์ ```page=``` เพื่อไล่หน้า 1,2,3,…\n",
    "\n",
    "    - HEADLESS — ตั้ง ```True``` เพื่อไม่แสดงหน้าต่างเบราว์เซอร์ (เหมาะกับ Colab)\n",
    "\n",
    "    - ควบคุมการเปลี่ยนหน้า: ```MAX_PAGES``` เป็นขีดจำกัด (หยุดก่อนถ้าหน้าที่ได้มาไม่มีสินค้าใหม่)\n",
    "\n",
    "    - ควบคุมการเลื่อนในแต่ละหน้า: ```PER_PAGE_MIN_ITEMS```, ```PER_PAGE_MAX_SCROLLS```, ```SCROLL_PAUSE_RANGE```\n",
    "\n",
    "    - Selector หลายแบบเพื่อกัน DOM เปลี่ยน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979e652c-3bc4-4cc5-b640-c93d08db35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(s: Optional[str]) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "def price_to_float(price_text: str) -> Optional[float]:\n",
    "    if not price_text:\n",
    "        return None\n",
    "    t = price_text.replace(\",\", \"\")\n",
    "    m = re.search(r\"(\\d+(?:\\.\\d+)?)\", t)\n",
    "    if not m:\n",
    "        return None\n",
    "    try:\n",
    "        return float(m.group(1))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def sold_to_number(sold_text: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Convert 'ขายแล้ว 1.2พัน', 'Sold 1.2k', '10K+', '3 หมื่น', '2.5 ล้าน+' to an int.\n",
    "    \"\"\"\n",
    "    if not sold_text:\n",
    "        return None\n",
    "    t = sold_text.lower().replace(\"+\", \"\").strip()\n",
    "    m = re.search(r\"(\\d+(?:\\.\\d+)?)\", t)\n",
    "    if not m:\n",
    "        return None\n",
    "    num = float(m.group(1))\n",
    "    if any(k in t for k in [\"k\", \"พัน\"]):   return int(num * 1_000)\n",
    "    if \"หมื่น\" in t:                        return int(num * 10_000)\n",
    "    if \"แสน\" in t:                          return int(num * 100_000)\n",
    "    if any(k in t for k in [\"m\", \"ล้าน\"]):  return int(num * 1_000_000)\n",
    "    return int(num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ae88c-205c-4ac8-9745-6e6c7fca305e",
   "metadata": {},
   "source": [
    " -```clean_text``` normalizes whitespace.\n",
    "\n",
    " -```price_to_float``` extracts a numeric price from strings like ```฿1,290``` → ```1290.0```.\n",
    "\n",
    " -```sold_to_number``` maps Thai/English multipliers (k/พัน/หมื่น/แสน/m/ล้าน) to an integer estimate.\n",
    "\n",
    "\n",
    "\n",
    " -```clean_text``` จัดรูปแบบช่องว่างให้เรียบร้อย\n",
    "\n",
    " -```price_to_float``` ดึงตัวเลขจากข้อความราคา เช่น ```฿1,290``` → ```1290.0```\n",
    "\n",
    " -```sold_to_number``` แปลงตัวคูณไทย/อังกฤษ (k/พัน/หมื่น/แสน/m/ล้าน) เป็นจำนวนเต็มโดยประมาณ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a63181-74fc-4ac9-ac2e-603e93a5f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_driver(headless: bool = HEADLESS) -> webdriver.Chrome:\n",
    "    opts = Options()\n",
    "    if headless:\n",
    "        opts.add_argument(\"--headless=new\")\n",
    "    opts.add_argument(\"--disable-gpu\")\n",
    "    opts.add_argument(\"--no-sandbox\")\n",
    "    opts.add_argument(\"--disable-dev-shm-usage\")\n",
    "    opts.add_argument(\"--window-size=1280,1600\")\n",
    "    opts.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/118.0.0.0 Safari/537.36\"\n",
    "    )\n",
    "    service = Service()  # Selenium Manager will handle the driver\n",
    "    return webdriver.Chrome(service=service, options=opts)\n",
    "\n",
    "def maybe_accept_cookies_or_popups(driver: webdriver.Chrome) -> None:\n",
    "    candidates = [\n",
    "        \"//button[contains(., 'ยอมรับ') or contains(., 'ตกลง') or contains(., 'Accept') or contains(., 'Agree')]\",\n",
    "        \"//a[contains(., 'ยอมรับ') or contains(., 'Accept')]\",\n",
    "        \"//button[contains(@class, 'close') or contains(@aria-label, 'close')]\",\n",
    "    ]\n",
    "    for xp in candidates:\n",
    "        try:\n",
    "            el = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, xp)))\n",
    "            el.click()\n",
    "            time.sleep(0.3)\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82f145a-9188-4a55-a7bc-60e295be984e",
   "metadata": {},
   "source": [
    " -```make_driver``` sets Chrome options and relies on Selenium Manager to find the right driver automatically.\n",
    "\n",
    " -```maybe_accept_cookies_or_popups``` tries common Thai/English buttons to dismiss cookie banners or modals; it’s okay if none are present.\n",
    "\n",
    "\n",
    "\n",
    " -```make_driver``` ตั้งค่า Chrome และให้ Selenium Manager จัดการไดรเวอร์ให้อัตโนมัติ\n",
    "\n",
    " -```maybe_accept_cookies_or_popups``` ลองกดปุ่มยอมรับ/ปิดป็อปอัป (ไทย/อังกฤษ) ถ้าไม่มี ก็ข้ามไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910644fb-304d-422e-9ee0-f22f08e00f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_results(driver: webdriver.Chrome, timeout: int = 20) -> None:\n",
    "    def any_selector_present(drv):\n",
    "        for css in PRODUCT_ANCHOR_CSS + NAME_CANDIDATES:\n",
    "            try:\n",
    "                if drv.find_elements(By.CSS_SELECTOR, css):\n",
    "                    return True\n",
    "            except Exception:\n",
    "                pass\n",
    "        return False\n",
    "    WebDriverWait(driver, timeout).until(lambda d: any_selector_present(d))\n",
    "\n",
    "def scroll_page_to_load(driver: webdriver.Chrome,\n",
    "                        min_items: int = PER_PAGE_MIN_ITEMS,\n",
    "                        max_scrolls: int = PER_PAGE_MAX_SCROLLS,\n",
    "                        pause_range: tuple = SCROLL_PAUSE_RANGE) -> None:\n",
    "    last_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    scrolls = 0\n",
    "    while scrolls < max_scrolls:\n",
    "        anchors = []\n",
    "        for css in PRODUCT_ANCHOR_CSS:\n",
    "            anchors.extend(driver.find_elements(By.CSS_SELECTOR, css))\n",
    "        if len(anchors) >= min_items:\n",
    "            break\n",
    "\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(*pause_range))\n",
    "\n",
    "        new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_h == last_h:\n",
    "            driver.execute_script(\"window.scrollBy(0, -400);\")\n",
    "            time.sleep(0.4)\n",
    "            driver.execute_script(\"window.scrollBy(0, 800);\")\n",
    "            time.sleep(random.uniform(*pause_range))\n",
    "            new_h = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_h == last_h:\n",
    "                break\n",
    "\n",
    "        last_h = new_h\n",
    "        scrolls += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54279f0-5871-4de4-aae2-d5cfbda44369",
   "metadata": {},
   "source": [
    " - ```wait_for_results``` blocks until at least one known product/name selector is found.\n",
    "\n",
    " - ```scroll_page_to_load``` lazily scrolls the page to trigger lazy-loading; stops when enough anchors are seen or max_scrolls reached (with small random pauses).\n",
    "\n",
    "\n",
    "\n",
    " - ```wait_for_results``` รอจนกว่าจะเห็น element ที่เป็นสินค้า/ชื่อสินค้า\n",
    "\n",
    " - ```scroll_page_to_load``` เลื่อนหน้าจอเพื่อโหลดรายการเพิ่ม หยุดเมื่อมี anchor สินค้าเพียงพอหรือครบจำนวนครั้งที่กำหนด (พักแบบสุ่มเล็กน้อย)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "835d3e85-ad19-418c-af61-fc6832928f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_select_first_text(node: BeautifulSoup, css_list: List[str]) -> str:\n",
    "    for css in css_list:\n",
    "        try:\n",
    "            found = node.select_one(css)\n",
    "            if found:\n",
    "                t = clean_text(found.get_text())\n",
    "                if t:\n",
    "                    return t\n",
    "        except Exception:\n",
    "            pass\n",
    "    return \"\"\n",
    "\n",
    "def parse_page_cards(page_html: str) -> List[Dict[str, Any]]:\n",
    "    soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "\n",
    "    # Collect anchors\n",
    "    anchors = []\n",
    "    for css in PRODUCT_ANCHOR_CSS:\n",
    "        anchors.extend(soup.select(css))\n",
    "\n",
    "    # Deduplicate by href and normalize to absolute URLs\n",
    "    seen, uniq = set(), []\n",
    "    for a in anchors:\n",
    "        href = a.get(\"href\") or \"\"\n",
    "        if not href:\n",
    "            continue\n",
    "        if href.startswith(\"//\"): href = \"https:\" + href\n",
    "        elif href.startswith(\"/\"): href = \"https://www.lazada.co.th\" + href\n",
    "        if href in seen:\n",
    "            continue\n",
    "        seen.add(href)\n",
    "        uniq.append((a, href))\n",
    "\n",
    "    rows = []\n",
    "    for a, href in uniq:\n",
    "        card = a\n",
    "        for _ in range(3):  # go up a bit to get the product card container\n",
    "            if card.parent:\n",
    "                card = card.parent\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        name = clean_text(a.get(\"title\")) or clean_text(a.get_text())\n",
    "        if not name:\n",
    "            name = soup_select_first_text(card, NAME_CANDIDATES)\n",
    "\n",
    "        price_text   = soup_select_first_text(card, PRICE_CANDIDATES)\n",
    "        sold_text    = soup_select_first_text(card, SOLD_CANDIDATES)\n",
    "        rating_text  = soup_select_first_text(card, RATING_CANDIDATES)\n",
    "        reviews_text = soup_select_first_text(card, REVIEWS_CANDIDATES)\n",
    "\n",
    "        if not price_text:\n",
    "            price_text = soup_select_first_text(soup, PRICE_CANDIDATES)\n",
    "        if not sold_text:\n",
    "            sold_text  = soup_select_first_text(soup, SOLD_CANDIDATES)\n",
    "\n",
    "        rows.append({\n",
    "            \"name\": name,\n",
    "            \"price_text\": price_text,\n",
    "            \"price\": price_to_float(price_text),\n",
    "            \"sold_text\": sold_text,\n",
    "            \"sold_est\": sold_to_number(sold_text) if sold_text else None,\n",
    "            \"rating_text\": rating_text,\n",
    "            \"reviews_text\": reviews_text,\n",
    "            \"product_url\": href,\n",
    "        })\n",
    "\n",
    "    rows = [r for r in rows if r[\"name\"] and r[\"product_url\"]]\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b8139-6cb3-407a-917d-b5bdc731acb8",
   "metadata": {},
   "source": [
    " - Finds all product anchors, dedupes by ```href```, normalizes URLs, then for each card extracts ```name```, ```price```, ```sold```, ```rating```, ```reviews``` with fallbacks.\n",
    "\n",
    " - Converts text fields to numeric ```price``` and ```sold_est``` when possible.\n",
    "\n",
    "\n",
    " - ดึงลิงก์สินค้าทั้งหมด, ลบซ้ำด้วย ```href```, ทำ URL ให้เป็นแบบสมบูรณ์ แล้วดึง ```name```, ```price```, ```sold```, ```rating```, ```reviews``` พร้อม fallback\n",
    "\n",
    " - แปลง ```price_text``` และ ```sold_text``` เป็นตัวเลข (```price```, ```sold_est```) เมื่อทำได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5744cca0-4f2e-4c0f-9ffc-d8916963679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lazada_all_pages(keyword: str,\n",
    "                            max_pages: int = MAX_PAGES,\n",
    "                            per_page_min_items: int = PER_PAGE_MIN_ITEMS,\n",
    "                            per_page_max_scrolls: int = PER_PAGE_MAX_SCROLLS,\n",
    "                            headless: bool = HEADLESS) -> pd.DataFrame:\n",
    "    driver = make_driver(headless=headless)\n",
    "    all_rows: List[Dict[str, Any]] = []\n",
    "    seen_urls = set()\n",
    "\n",
    "    try:\n",
    "        for page in range(1, max_pages + 1):\n",
    "            url = BASE_SEARCH_URL.format(query=quote_plus(keyword), page=page)\n",
    "            driver.get(url)\n",
    "            maybe_accept_cookies_or_popups(driver)\n",
    "\n",
    "            try:\n",
    "                wait_for_results(driver, timeout=20)\n",
    "            except Exception:\n",
    "                # If page loads but shows no products, stop\n",
    "                print(f\"[Page {page}] No results detected. Stopping.\")\n",
    "                break\n",
    "\n",
    "            # Scroll within this page to load items\n",
    "            scroll_page_to_load(\n",
    "                driver,\n",
    "                min_items=per_page_min_items,\n",
    "                max_scrolls=per_page_max_scrolls,\n",
    "                pause_range=SCROLL_PAUSE_RANGE,\n",
    "            )\n",
    "\n",
    "            html = driver.page_source\n",
    "            rows = parse_page_cards(html)\n",
    "\n",
    "            # Keep only new URLs to detect end of pagination\n",
    "            new_rows = []\n",
    "            for r in rows:\n",
    "                u = r[\"product_url\"]\n",
    "                if u not in seen_urls:\n",
    "                    seen_urls.add(u)\n",
    "                    new_rows.append(r)\n",
    "\n",
    "            print(f\"[Page {page}] parsed {len(rows)} rows, new {len(new_rows)}\")\n",
    "\n",
    "            if not new_rows:\n",
    "                # No new items on this page → likely end of pagination or duplicate page\n",
    "                print(f\"[Page {page}] No new products found. Stopping.\")\n",
    "                break\n",
    "\n",
    "            all_rows.extend(new_rows)\n",
    "\n",
    "            # polite pause before next page\n",
    "            time.sleep(random.uniform(*BETWEEN_PAGE_PAUSE))\n",
    "\n",
    "        df = pd.DataFrame(all_rows)\n",
    "        if not df.empty:\n",
    "            df = df.drop_duplicates(subset=[\"product_url\"]).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb620291-cd61-45c7-9bcb-378370f7246b",
   "metadata": {},
   "source": [
    " - Opens Chrome once, then loops ```page=1..MAX_PAGES```.\n",
    "\n",
    " - Builds the search URL with ```q=<keyword>&page=<page>```.\n",
    "\n",
    " - Waits for results, scrolls each page to load all items, parses them, and keeps only new URLs (helps detect the last page).\n",
    "\n",
    " - Stops when a page returns no new products or when ```MAX_PAGES``` is reached.\n",
    "\n",
    " - Returns a deduplicated DataFrame of all pages.\n",
    "\n",
    "\n",
    "\n",
    " - เปิด Chrome หนึ่งครั้ง แล้ววนหน้า ```page=1..MAX_PAGES```\n",
    "\n",
    " - สร้าง URL ```q=<keyword>&page=<page>```\n",
    "\n",
    " - รอผลลัพธ์, เลื่อนหน้าภายในหน้านั้น เพื่อโหลดสินค้าทั้งหมด, แปลง HTML เป็นแถวข้อมูล และ เก็บเฉพาะ URL ใหม่ (เพื่อเช็คว่าไปสุดหน้าสุดท้ายแล้วหรือยัง)\n",
    "\n",
    " - หยุดเมื่อไม่พบสินค้าใหม่ในหน้านั้น หรือครบ ```MAX_PAGES```\n",
    "\n",
    " - คืนค่า DataFrame ที่ลบซ้ำแล้ว รวมทุกหน้า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc47662e-da87-4f1f-af71-808751485df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Page 1] parsed 43 rows, new 43\n",
      "[Page 2] parsed 43 rows, new 13\n",
      "[Page 3] parsed 43 rows, new 34\n",
      "[Page 4] parsed 43 rows, new 38\n",
      "[Page 5] parsed 43 rows, new 40\n",
      "[Page 6] parsed 43 rows, new 40\n",
      "[Page 7] parsed 43 rows, new 40\n",
      "[Page 8] parsed 43 rows, new 40\n",
      "[Page 9] parsed 43 rows, new 40\n",
      "[Page 10] parsed 43 rows, new 39\n",
      "[Page 11] parsed 43 rows, new 40\n",
      "[Page 12] parsed 43 rows, new 40\n",
      "[Page 13] parsed 43 rows, new 40\n",
      "[Page 14] parsed 43 rows, new 40\n",
      "[Page 15] parsed 43 rows, new 40\n",
      "[Page 16] parsed 43 rows, new 40\n",
      "[Page 17] parsed 43 rows, new 40\n",
      "[Page 18] parsed 43 rows, new 40\n",
      "[Page 19] parsed 43 rows, new 40\n",
      "[Page 20] parsed 43 rows, new 40\n",
      "[Page 21] parsed 43 rows, new 40\n",
      "[Page 22] parsed 43 rows, new 40\n",
      "[Page 23] parsed 43 rows, new 40\n",
      "[Page 24] parsed 43 rows, new 40\n",
      "[Page 25] parsed 43 rows, new 40\n",
      "[Page 26] parsed 43 rows, new 40\n",
      "[Page 27] parsed 43 rows, new 40\n",
      "[Page 28] parsed 43 rows, new 40\n",
      "[Page 29] parsed 43 rows, new 40\n",
      "[Page 30] parsed 43 rows, new 40\n",
      "[Page 31] parsed 43 rows, new 40\n",
      "[Page 32] parsed 43 rows, new 40\n",
      "[Page 33] parsed 43 rows, new 40\n",
      "[Page 34] parsed 43 rows, new 40\n",
      "[Page 35] parsed 43 rows, new 40\n",
      "[Page 36] parsed 43 rows, new 40\n",
      "[Page 37] No results detected. Stopping.\n",
      "Total unique products: 1407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price_text</th>\n",
       "      <th>price</th>\n",
       "      <th>sold_text</th>\n",
       "      <th>sold_est</th>\n",
       "      <th>rating_text</th>\n",
       "      <th>reviews_text</th>\n",
       "      <th>product_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dr.PONG Astaxanthin 6 mg AstaREAL from Japan ด...</td>\n",
       "      <td>฿379.00</td>\n",
       "      <td>379.00</td>\n",
       "      <td>100.4K ชิ้น(29581)ปทุมธานี</td>\n",
       "      <td>100400.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i3640665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr.PONG Special Set Astaxanthin แอสตาแซนธิน 3 ...</td>\n",
       "      <td>฿1,099.00</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>3.5K ชิ้น(1584)ปทุมธานี</td>\n",
       "      <td>3500.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5372715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr.PONG เซตสุดคุ้ม 008 : เซตอาหารเสริมขายดี (ว...</td>\n",
       "      <td>฿849.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>784 ชิ้น(361)ปทุมธานี</td>\n",
       "      <td>784.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5556217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( Pack 2 ) VISTRA ASTAXANTHIN 6 MG PLUS VITAMI...</td>\n",
       "      <td>฿1,232.00</td>\n",
       "      <td>1232.00</td>\n",
       "      <td>3.4K ชิ้น(1388)นนทบุรี</td>\n",
       "      <td>3400.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5014701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FITWHEY ASTAXANTHIN 6MG + COQ10 (30 SOFTGELS) ...</td>\n",
       "      <td>฿199.00</td>\n",
       "      <td>199.00</td>\n",
       "      <td>7.4K ชิ้น(2373)สมุทรปราการ</td>\n",
       "      <td>7400.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5067987...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(EXP: 23/11/2025) Astaxanthin 6 MG + CoQ10 แอส...</td>\n",
       "      <td>฿99.00</td>\n",
       "      <td>99.00</td>\n",
       "      <td>116 ชิ้น(60)สมุทรปราการ</td>\n",
       "      <td>116.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i4898321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ร้านบริษัท]INZENT (เซต 2 กระปุก) คู่จิ้น ASTA...</td>\n",
       "      <td>฿509.04</td>\n",
       "      <td>509.04</td>\n",
       "      <td>นครราชสีมา</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5855061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>บีลีฟ แอสตาแซนธิน 8 มก. ( แอสตาอิงฟ้า ) Beleaf...</td>\n",
       "      <td>฿2,112.32</td>\n",
       "      <td>2112.32</td>\n",
       "      <td>นนทบุรี</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5855146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KIRKLAND 24mg Natural Astaxanthin Capsules สนั...</td>\n",
       "      <td>฿223.00</td>\n",
       "      <td>223.00</td>\n",
       "      <td>255 ชิ้น(79)เชียงใหม่</td>\n",
       "      <td>255.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5688665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Astaxanthin 12 mg Softgels สนับสนุนสุขภาพภูมิค...</td>\n",
       "      <td>฿197.00</td>\n",
       "      <td>197.00</td>\n",
       "      <td>1.2K ชิ้น(423)เชียงใหม่</td>\n",
       "      <td>1200.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>https://www.lazada.co.th/products/pdp-i5661343...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name price_text    price  \\\n",
       "0  Dr.PONG Astaxanthin 6 mg AstaREAL from Japan ด...    ฿379.00   379.00   \n",
       "1  Dr.PONG Special Set Astaxanthin แอสตาแซนธิน 3 ...  ฿1,099.00  1099.00   \n",
       "2  Dr.PONG เซตสุดคุ้ม 008 : เซตอาหารเสริมขายดี (ว...    ฿849.00   849.00   \n",
       "3  ( Pack 2 ) VISTRA ASTAXANTHIN 6 MG PLUS VITAMI...  ฿1,232.00  1232.00   \n",
       "4  FITWHEY ASTAXANTHIN 6MG + COQ10 (30 SOFTGELS) ...    ฿199.00   199.00   \n",
       "5  (EXP: 23/11/2025) Astaxanthin 6 MG + CoQ10 แอส...     ฿99.00    99.00   \n",
       "6  [ร้านบริษัท]INZENT (เซต 2 กระปุก) คู่จิ้น ASTA...    ฿509.04   509.04   \n",
       "7  บีลีฟ แอสตาแซนธิน 8 มก. ( แอสตาอิงฟ้า ) Beleaf...  ฿2,112.32  2112.32   \n",
       "8  KIRKLAND 24mg Natural Astaxanthin Capsules สนั...    ฿223.00   223.00   \n",
       "9  Astaxanthin 12 mg Softgels สนับสนุนสุขภาพภูมิค...    ฿197.00   197.00   \n",
       "\n",
       "                    sold_text  sold_est rating_text reviews_text  \\\n",
       "0  100.4K ชิ้น(29581)ปทุมธานี  100400.0                            \n",
       "1     3.5K ชิ้น(1584)ปทุมธานี    3500.0                            \n",
       "2       784 ชิ้น(361)ปทุมธานี     784.0                            \n",
       "3      3.4K ชิ้น(1388)นนทบุรี    3400.0                            \n",
       "4  7.4K ชิ้น(2373)สมุทรปราการ    7400.0                            \n",
       "5     116 ชิ้น(60)สมุทรปราการ     116.0                            \n",
       "6                  นครราชสีมา       NaN                            \n",
       "7                     นนทบุรี       NaN                            \n",
       "8       255 ชิ้น(79)เชียงใหม่     255.0                            \n",
       "9     1.2K ชิ้น(423)เชียงใหม่    1200.0                            \n",
       "\n",
       "                                         product_url  \n",
       "0  https://www.lazada.co.th/products/pdp-i3640665...  \n",
       "1  https://www.lazada.co.th/products/pdp-i5372715...  \n",
       "2  https://www.lazada.co.th/products/pdp-i5556217...  \n",
       "3  https://www.lazada.co.th/products/pdp-i5014701...  \n",
       "4  https://www.lazada.co.th/products/pdp-i5067987...  \n",
       "5  https://www.lazada.co.th/products/pdp-i4898321...  \n",
       "6  https://www.lazada.co.th/products/pdp-i5855061...  \n",
       "7  https://www.lazada.co.th/products/pdp-i5855146...  \n",
       "8  https://www.lazada.co.th/products/pdp-i5688665...  \n",
       "9  https://www.lazada.co.th/products/pdp-i5661343...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: lazada_astaxanthin_allpages.csv\n"
     ]
    }
   ],
   "source": [
    "df = scrape_lazada_all_pages(\n",
    "    keyword=KEYWORD,\n",
    "    max_pages=MAX_PAGES,\n",
    "    per_page_min_items=PER_PAGE_MIN_ITEMS,\n",
    "    per_page_max_scrolls=PER_PAGE_MAX_SCROLLS,\n",
    "    headless=HEADLESS,\n",
    ")\n",
    "\n",
    "print(f\"Total unique products: {len(df)}\")\n",
    "display(df.head(10))\n",
    "\n",
    "out_path = f\"lazada_{KEYWORD}_allpages.csv\"\n",
    "df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d979a3-bc46-4a96-ac1d-fd24e4d7c2cd",
   "metadata": {},
   "source": [
    " - Runs the full crawl over every page for the keyword, shows a preview, and saves to ```lazada_astaxanthin_allpages.csv``` (UTF-8 with BOM so Thai displays correctly in Excel).\n",
    "\n",
    "\n",
    " - รันการดึงข้อมูลครบทุกหน้า ตามคำค้นที่กำหนด แสดงตัวอย่างตาราง และบันทึกเป็น ```lazada_astaxanthin_allpages.csv``` (เข้ารหัส UTF-8 พร้อม BOM เพื่อให้ Excel อ่านภาษาไทยได้ถูกต้อง)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ba3fc-0af8-43ea-8ca7-7768e84b4ee7",
   "metadata": {},
   "source": [
    "### Notes & troubleshooting\n",
    "\n",
    "\n",
    "\n",
    " - If you see “No results detected” on page 1, Lazada’s DOM or blocking behavior may have changed; increase timeouts or adjust selectors (```PRODUCT_ANCHOR_CSS```, etc.).\n",
    "\n",
    " - If you get very few results, increase ```PER_PAGE_MIN_ITEMS``` or ```PER_PAGE_MAX_SCROLLS```.\n",
    "\n",
    " - On hosted environments (Colab), set ```HEADLESS = True```.\n",
    "\n",
    "\n",
    "\n",
    " - ถ้าขึ้น “No results detected” ตั้งแต่หน้าแรก อาจเกิดจาก DOM/การบล็อกของเว็บ ให้เพิ่มเวลา timeout หรือปรับ selector (```PRODUCT_ANCHOR_CSS``` ฯลฯ)\n",
    "\n",
    " - ถ้าข้อมูลน้อย ให้เพิ่ม ```PER_PAGE_MIN_ITEMS``` หรือ ```PER_PAGE_MAX_SCROLLS```\n",
    "\n",
    " - ถ้าใช้ Colab แนะนำ ```HEADLESS = True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877c7335-3067-4975-b0ae-ef9a3d4089be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
